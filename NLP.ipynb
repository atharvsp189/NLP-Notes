{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1ohwFYQB3Lm",
        "outputId": "42c9829c-d199-45a0-b6a8-1e667195764e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization**"
      ],
      "metadata": {
        "id": "Kl0Y0pRrHhRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"\"\"This is Random Paragraph. Really Excited for NLP. Transformers Excites me a lot.\"\"\"\n",
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvzzAacFCBBV",
        "outputId": "ca7a0c09-07aa-4c1c-deb6-9c721647cb5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is Random Paragraph. Really Excited for NLP. Transformers Excites me a lot.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = nltk.sent_tokenize(corpus)\n",
        "print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvtToQB3CKJ8",
        "outputId": "6fc2df5a-6307-4096-8688-ec2485f8c199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is Random Paragraph.', 'Really Excited for NLP.', 'Transformers Excites me a lot.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3qoeSw-D5tF",
        "outputId": "83f34f8c-edf6-45b0-8a7a-eb7eebecdc40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in sentence:\n",
        "  tokens = nltk.word_tokenize(sent)\n",
        "  tagged = nltk.pos_tag(tokens)\n",
        "  print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNQeh66mCefs",
        "outputId": "565be7c1-b45b-4459-921d-489054f56e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('This', 'DT'), ('is', 'VBZ'), ('Random', 'NNP'), ('Paragraph', 'NNP'), ('.', '.')]\n",
            "[('Really', 'RB'), ('Excited', 'VBN'), ('for', 'IN'), ('NLP', 'NNP'), ('.', '.')]\n",
            "[('Transformers', 'NNS'), ('Excites', 'VBZ'), ('me', 'PRP'), ('a', 'DT'), ('lot', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in sentence:\n",
        "  tokens = nltk.wordpunct_tokenize(sent)\n",
        "  tagged = nltk.pos_tag(tokens)\n",
        "  print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjKCIEBFDuJS",
        "outputId": "79155d12-e211-4103-8360-4dae4c6b5264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('This', 'DT'), ('is', 'VBZ'), ('Random', 'NNP'), ('Paragraph', 'NNP'), ('.', '.')]\n",
            "[('Really', 'RB'), ('Excited', 'VBN'), ('for', 'IN'), ('NLP', 'NNP'), ('.', '.')]\n",
            "[('Transformers', 'NNS'), ('Excites', 'VBZ'), ('me', 'PRP'), ('a', 'DT'), ('lot', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokenizer.tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpPkZwRsEeNW",
        "outputId": "fad48f62-d967-4b74-84fe-2b5a52e8d8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'Random',\n",
              " 'Paragraph.',\n",
              " 'Really',\n",
              " 'Excited',\n",
              " 'for',\n",
              " 'NLP.',\n",
              " 'Transformers',\n",
              " 'Excites',\n",
              " 'me',\n",
              " 'a',\n",
              " 'lot',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stemming**"
      ],
      "metadata": {
        "id": "dX28Vp5QHvNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BjWPTwVeRQyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\", \"eat\", \"eating\", \"Eaten\"]"
      ],
      "metadata": {
        "id": "Qeq9PjdwEyJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PorterStemmer\n",
        "#  It is based on the idea that the suffixes in the English language are made up of a combination of smaller and simpler suffixes. This stemmer is known for its speed and simplicity.\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "for word in words:\n",
        "  print(word, \":\", ps.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YppWfP7OHty-",
        "outputId": "d9dac1ec-1660-4c8c-a34f-7b883e623256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program : program\n",
            "programs : program\n",
            "programer : program\n",
            "programing : program\n",
            "programers : program\n",
            "eat : eat\n",
            "eating : eat\n",
            "Eaten : eaten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"eaten : \", ps.stem(\"eaten\"))\n",
        "print(\"jump : \", ps.stem(\"jump\"))\n",
        "print(\"cried : \", ps.stem(\"cried\"))\n",
        "print(\"laughed : \", ps.stem(\"laughed\"))\n",
        "print(\"fairly : \", ps.stem(\"fairly\"))\n",
        "print(\"sporty : \", ps.stem(\"sporty\"))\n",
        "print(\"goes : \", ps.stem(\"goes\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woDMAKPBJjVL",
        "outputId": "4873ce94-287d-464d-af3e-a2c80f555e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eaten :  eaten\n",
            "jump :  jump\n",
            "cried :  cri\n",
            "laughed :  laugh\n",
            "fairly :  fairli\n",
            "sporty :  sporti\n",
            "goes :  goe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RegexpStemmer class\n",
        "# The Regexp Stemmer, or Regular Expression Stemmer, is a stemming algorithm that utilizes regular expressions to identify and remove suffixes from words. It allows users to define custom rules for stemming by specifying patterns to match and remove.\n",
        "from nltk.stem import RegexpStemmer\n",
        "rs = RegexpStemmer('ing$|s$|able$|ed$', min=4)\n",
        "for word in words:\n",
        "  print(word, \":\", rs.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2itqaxjKbib",
        "outputId": "088f9ed4-f56d-4eda-ced1-fb27f1bc1cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program : program\n",
            "programs : program\n",
            "programer : programer\n",
            "programing : program\n",
            "programers : programer\n",
            "eat : eat\n",
            "eating : eat\n",
            "Eaten : Eaten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"eating : \", rs.stem(\"eating\"))\n",
        "print(\"jumped : \", rs.stem(\"jumped\"))\n",
        "print(\"cried : \", rs.stem(\"cried\"))\n",
        "print(\"laughable : \", rs.stem(\"laughable\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Igx2cEZLJc4",
        "outputId": "837594b7-3e7a-4e0d-8ffb-8c656543cbce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating :  eat\n",
            "jumped :  jump\n",
            "cried :  cri\n",
            "laughable :  laugh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Snowball Stemmer\n",
        "# Performs better than PorterStemmer, Multingual, Porter2Stemmer, Improves Performance When Addes to PorterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "ss = SnowballStemmer(language='english')\n",
        "\n",
        "for word in words:\n",
        "  print(word, \":\", ss.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QaOkozxMI31",
        "outputId": "06256cb3-1a87-48b9-bb25-7f39214e7a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program : program\n",
            "programs : program\n",
            "programer : program\n",
            "programing : program\n",
            "programers : program\n",
            "eat : eat\n",
            "eating : eat\n",
            "Eaten : eaten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"eating : \", ss.stem(\"eating\"))\n",
        "print(\"jumped : \", ss.stem(\"jumped\"))\n",
        "print(\"cried : \", ss.stem(\"cried\"))\n",
        "print(\"laughed : \", ss.stem(\"laughed\"))\n",
        "print(\"fairly : \", ss.stem(\"fairly\"))\n",
        "print(\"sporty : \", ss.stem(\"sporty\"))\n",
        "print(\"goes : \", ss.stem(\"goes\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqS2vCwTOppk",
        "outputId": "32b66fee-f0ad-4c80-861c-fecd8a9ab888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating :  eat\n",
            "jumped :  jump\n",
            "cried :  cri\n",
            "laughed :  laugh\n",
            "fairly :  fair\n",
            "sporty :  sporti\n",
            "goes :  goe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lemmatization**"
      ],
      "metadata": {
        "id": "7bBhT3u2REIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lm = WordNetLemmatizer()\n",
        "for word in words:\n",
        "  print(word, \":\", lm.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdCXx3R9OtxH",
        "outputId": "5600fa7c-c01a-4ddd-c332-eb58326166ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program : program\n",
            "programs : program\n",
            "programmer : programmer\n",
            "programming : programming\n",
            "programmers : programmer\n",
            "eat : eat\n",
            "eating : eating\n",
            "Eaten : Eaten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"eaten : \", lm.lemmatize(\"eaten\"))\n",
        "print(\"jumped : \", lm.lemmatize(\"jumped\", 'v'))\n",
        "print(\"cried : \", lm.lemmatize(\"cried\", 'v'))\n",
        "print(\"laughed : \", lm.lemmatize(\"laughed\"))\n",
        "print(\"fairly : \", lm.lemmatize(\"fairly\", pos='v'))\n",
        "print(\"sporty : \", lm.lemmatize(\"sporty\"))\n",
        "print(\"goes : \", lm.lemmatize(\"goes\"))\n",
        "\n",
        "print(\"rocks :\", lm.lemmatize(\"rocks\"))\n",
        "print(\"corpora :\", lm.lemmatize(\"corpora\"))\n",
        "\n",
        "# a denotes adjective in \"pos\"\n",
        "print(\"better :\", lm.lemmatize(\"better\", pos=\"a\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh42L2y9Tisa",
        "outputId": "4123e056-f513-4255-c62f-d7afafa51c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eaten :  eaten\n",
            "jumped :  jump\n",
            "cried :  cry\n",
            "laughed :  laughed\n",
            "fairly :  fairly\n",
            "sporty :  sporty\n",
            "goes :  go\n",
            "rocks : rock\n",
            "corpora : corpus\n",
            "better : good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Pos\n",
        "Noun - n\n",
        "Verb - v\n",
        "adjective - a\n",
        "adverb - r\n",
        "'''"
      ],
      "metadata": {
        "id": "vmgWd7TsTsW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import these modules\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
        "\n",
        "# a denotes adjective in \"pos\"\n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos=\"a\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6CxSuyJUEb1",
        "outputId": "a8e81e0a-5020-45a6-d9f6-f206e0cdcc79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rocks : rock\n",
            "corpora : corpus\n",
            "better : good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4vfptizWXLFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stopwords\n"
      ],
      "metadata": {
        "id": "sxDLd_PRWe5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"The sun dipped below the horizon, casting a warm glow over the quiet town. Birds chirped softly as the last rays of light danced on the rippling surface of the river. Along the narrow streets, people bustled about, preparing for the evening ahead. Children laughed as they played under the dimming sky, their joy echoing through the alleys. Meanwhile, the smell of freshly baked bread wafted from a nearby bakery, filling the air with a comforting aroma. The world seemed to slow down in this moment, as if time itself was taking a breath before the night fully embraced the town.\"\"\""
      ],
      "metadata": {
        "id": "6xQYvIU-XP-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V4xGmYmN4Ma",
        "outputId": "550cef9b-59de-4c56-ffc7-31afc4917ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5bbNmeBN6cF",
        "outputId": "0e1ae646-7386-472e-a9c5-f59ae020368d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "jnvKQ0Q9OZcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = SnowballStemmer(language='english')"
      ],
      "metadata": {
        "id": "bpcR-C82PitZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Apply Stopwords and filter and the stemming\n",
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [ss.stem(word) for word in words if word not in (stopwords.words('english'))]\n",
        "  sentences[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "5mE8Yx_CO4hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UyMDUnIQPK9",
        "outputId": "057a512c-a872-4790-acd7-95c8e0388a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the sun dip horizon , cast warm glow quiet town .',\n",
              " 'bird chirp soft last ray light danc rippl surfac river .',\n",
              " 'along narrow street , peopl bustl , prepar even ahead .',\n",
              " 'children laugh play dim sky , joy echo alley .',\n",
              " 'meanwhil , smell fresh bake bread waft nearbi bakeri , fill air comfort aroma .',\n",
              " 'the world seem slow moment , time take breath night fulli embrac town .']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmaParagraph = \"\"\"The sun dipped below the horizon, casting a warm glow over the quiet town. Birds chirped softly as the last rays of light danced on the rippling surface of the river. Along the narrow streets, people bustled about, preparing for the evening ahead. Children laughed as they played under the dimming sky, their joy echoing through the alleys. Meanwhile, the smell of freshly baked bread wafted from a nearby bakery, filling the air with a comforting aroma. The world seemed to slow down in this moment, as if time itself was taking a breath before the night fully embraced the town.\"\"\""
      ],
      "metadata": {
        "id": "jhWONg05SYqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmaSentence = nltk.sent_tokenize(lemmaParagraph)"
      ],
      "metadata": {
        "id": "O8nQbMi6SdsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lm = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "NbkeAxbXR0nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lemma Senetnce\n",
        "## Apply Stopwords and filter and the stemming\n",
        "for i in range(len(lemmaSentence)):\n",
        "  words = nltk.word_tokenize(lemmaSentence[i])\n",
        "  words = [ss.stem(word) for word in words if word not in (stopwords.words('english'))]\n",
        "  lemmaSentence[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "JT1qT7_gQcUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmaSentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G9B2PqFS6uH",
        "outputId": "5497094e-8466-4592-dc51-b89c74884fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the sun dip horizon , cast warm glow quiet town .',\n",
              " 'bird chirp soft last ray light danc rippl surfac river .',\n",
              " 'along narrow street , peopl bustl , prepar even ahead .',\n",
              " 'children laugh play dim sky , joy echo alley .',\n",
              " 'meanwhil , smell fresh bake bread waft nearbi bakeri , fill air comfort aroma .',\n",
              " 'the world seem slow moment , time take breath night fulli embrac town .']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POS Tagging"
      ],
      "metadata": {
        "id": "0B-mflfdYcJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iynm5VYBWYbC",
        "outputId": "04a1b08a-d3fc-4adf-a566-7d6c69a478f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words ={}\n",
        "for sent in lemmaSentence:\n",
        "  tokens = nltk.word_tokenize(sent)\n",
        "  for word in tokens:\n",
        "    words[word] = nltk.pos_tag([word])"
      ],
      "metadata": {
        "id": "OfJQYk3tS-Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIk2p3EaV4g3",
        "outputId": "0722b97d-df09-4129-b715-43c4d657f71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': [('the', 'DT')],\n",
              " 'sun': [('sun', 'NN')],\n",
              " 'dip': [('dip', 'NN')],\n",
              " 'horizon': [('horizon', 'NN')],\n",
              " ',': [(',', ',')],\n",
              " 'cast': [('cast', 'NN')],\n",
              " 'warm': [('warm', 'NN')],\n",
              " 'glow': [('glow', 'NN')],\n",
              " 'quiet': [('quiet', 'JJ')],\n",
              " 'town': [('town', 'NN')],\n",
              " '.': [('.', '.')],\n",
              " 'bird': [('bird', 'NN')],\n",
              " 'chirp': [('chirp', 'NN')],\n",
              " 'soft': [('soft', 'JJ')],\n",
              " 'last': [('last', 'JJ')],\n",
              " 'ray': [('ray', 'NN')],\n",
              " 'light': [('light', 'NN')],\n",
              " 'danc': [('danc', 'NN')],\n",
              " 'rippl': [('rippl', 'NN')],\n",
              " 'surfac': [('surfac', 'NN')],\n",
              " 'river': [('river', 'NN')],\n",
              " 'along': [('along', 'IN')],\n",
              " 'narrow': [('narrow', 'NN')],\n",
              " 'street': [('street', 'NN')],\n",
              " 'peopl': [('peopl', 'NN')],\n",
              " 'bustl': [('bustl', 'NN')],\n",
              " 'prepar': [('prepar', 'NN')],\n",
              " 'even': [('even', 'RB')],\n",
              " 'ahead': [('ahead', 'RB')],\n",
              " 'children': [('children', 'NNS')],\n",
              " 'laugh': [('laugh', 'NN')],\n",
              " 'play': [('play', 'NN')],\n",
              " 'dim': [('dim', 'NN')],\n",
              " 'sky': [('sky', 'NN')],\n",
              " 'joy': [('joy', 'NN')],\n",
              " 'echo': [('echo', 'NN')],\n",
              " 'alley': [('alley', 'NN')],\n",
              " 'meanwhil': [('meanwhil', 'NN')],\n",
              " 'smell': [('smell', 'NN')],\n",
              " 'fresh': [('fresh', 'JJ')],\n",
              " 'bake': [('bake', 'NN')],\n",
              " 'bread': [('bread', 'NN')],\n",
              " 'waft': [('waft', 'NN')],\n",
              " 'nearbi': [('nearbi', 'NN')],\n",
              " 'bakeri': [('bakeri', 'NN')],\n",
              " 'fill': [('fill', 'NN')],\n",
              " 'air': [('air', 'NN')],\n",
              " 'comfort': [('comfort', 'NN')],\n",
              " 'aroma': [('aroma', 'NN')],\n",
              " 'world': [('world', 'NN')],\n",
              " 'seem': [('seem', 'NN')],\n",
              " 'slow': [('slow', 'VB')],\n",
              " 'moment': [('moment', 'NN')],\n",
              " 'time': [('time', 'NN')],\n",
              " 'take': [('take', 'VB')],\n",
              " 'breath': [('breath', 'NN')],\n",
              " 'night': [('night', 'NN')],\n",
              " 'fulli': [('fulli', 'NN')],\n",
              " 'embrac': [('embrac', 'NN')]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition (NER)"
      ],
      "metadata": {
        "id": "y9TNoFusYo16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Person, Place, Date, Time, Money, Oraganization, Percent"
      ],
      "metadata": {
        "id": "gNuOnTkwY0IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"The sun dipped below the horizon, casting a warm glow over the quiet town. Birds chirped softly as the last rays of light danced on the rippling surface of the river. Along the narrow streets, people bustled about, preparing for the evening ahead. Children laughed as they played under the dimming sky, their joy echoing through the alleys. Meanwhile, the smell of freshly baked bread wafted from a nearby bakery, filling the air with a comforting aroma. The world seemed to slow down in this moment, as if time itself was taking a breath before the night fully embraced the town.\"\"\""
      ],
      "metadata": {
        "id": "wcCWSyS-WiBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = nltk.word_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "daqXaBplZB5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged = nltk.pos_tag(words)"
      ],
      "metadata": {
        "id": "Xj8Z9PiDZKax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8f-wBBmZpMQ",
        "outputId": "c38bb268-bfc1-42f7-ef9e-7f3aefa33515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.ne_chunk(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "CzS_iQLgZQr-",
        "outputId": "86a12594-d871-48c9-b34b-9ef8939e75b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'svgling'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tree/tree.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0msvgling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdraw_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdraw_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_svg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'svgling'"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tree('S', [('The', 'DT'), ('sun', 'NN'), ('dipped', 'VBD'), ('below', 'IN'), ('the', 'DT'), ('horizon', 'NN'), (',', ','), ('casting', 'VBG'), ('a', 'DT'), ('warm', 'JJ'), ('glow', 'NN'), ('over', 'IN'), ('the', 'DT'), ('quiet', 'JJ'), ('town', 'NN'), ('.', '.'), Tree('PERSON', [('Birds', 'NNP')]), ('chirped', 'VBD'), ('softly', 'RB'), ('as', 'IN'), ('the', 'DT'), ('last', 'JJ'), ('rays', 'NNS'), ('of', 'IN'), ('light', 'NN'), ('danced', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('rippling', 'VBG'), ('surface', 'NN'), ('of', 'IN'), ('the', 'DT'), ('river', 'NN'), ('.', '.'), ('Along', 'IN'), ('the', 'DT'), ('narrow', 'JJ'), ('streets', 'NNS'), (',', ','), ('people', 'NNS'), ('bustled', 'VBD'), ('about', 'RB'), (',', ','), ('preparing', 'VBG'), ('for', 'IN'), ('the', 'DT'), ('evening', 'NN'), ('ahead', 'RB'), ('.', '.'), Tree('PERSON', [('Children', 'NNP')]), ('laughed', 'VBD'), ('as', 'IN'), ('they', 'PRP'), ('played', 'VBD'), ('under', 'IN'), ('the', 'DT'), ('dimming', 'NN'), ('sky', 'NN'), (',', ','), ('their', 'PRP$'), ('joy', 'NN'), ('echoing', 'VBG'), ('through', 'IN'), ('the', 'DT'), ('alleys', 'NNS'), ('.', '.'), ('Meanwhile', 'RB'), (',', ','), ('the', 'DT'), ('smell', 'NN'), ('of', 'IN'), ('freshly', 'JJ'), ('baked', 'VBN'), ('bread', 'NN'), ('wafted', 'VBN'), ('from', 'IN'), ('a', 'DT'), ('nearby', 'JJ'), ('bakery', 'NN'), (',', ','), ('filling', 'VBG'), ('the', 'DT'), ('air', 'NN'), ('with', 'IN'), ('a', 'DT'), ('comforting', 'VBG'), ('aroma', 'NN'), ('.', '.'), ('The', 'DT'), ('world', 'NN'), ('seemed', 'VBD'), ('to', 'TO'), ('slow', 'VB'), ('down', 'RP'), ('in', 'IN'), ('this', 'DT'), ('moment', 'NN'), (',', ','), ('as', 'IN'), ('if', 'IN'), ('time', 'NN'), ('itself', 'PRP'), ('was', 'VBD'), ('taking', 'VBG'), ('a', 'DT'), ('breath', 'NN'), ('before', 'IN'), ('the', 'DT'), ('night', 'NN'), ('fully', 'RB'), ('embraced', 'VBD'), ('the', 'DT'), ('town', 'NN'), ('.', '.')])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from nltk.tree import Tree\n",
        "\n",
        "# Convert to tree object and display with Matplotlib\n",
        "chunked = nltk.ne_chunk(tagged)\n",
        "tree = Tree.fromstring(str(chunked))\n",
        "tree.pretty_print()  # Text representation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxJhz2vqZe4J",
        "outputId": "9ec93e24-2baa-4540-e988-42d01646ca95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     S                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "   __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________|_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________        \n",
            "  |      |        |         |       |        |       |       |       |      |       |       |      |       |        |     |       |          |       |     |       |       |       |      |         |        |     |         |           |        |     |       |      |     |       |        |          |       |      |           |         |      |        |         |      |        |         |      |       |        |      |         |         |       |        |        |     |      |        |         |          |        |        |       |       |        |    |       |       |       |          |        |         |         |     |       |         |      |       |        |      |       |     |         |           |      |    |       |         |        |      |       |      |      |        |      |    |     |      |        |         |        |       |       |         |       |       |        |          |         |       |     |    PERSON     PERSON   \n",
            "  |      |        |         |       |        |       |       |       |      |       |       |      |       |        |     |       |          |       |     |       |       |       |      |         |        |     |         |           |        |     |       |      |     |       |        |          |       |      |           |         |      |        |         |      |        |         |      |       |        |      |         |         |       |        |        |     |      |        |         |          |        |        |       |       |        |    |       |       |       |          |        |         |         |     |       |         |      |       |        |      |       |     |         |           |      |    |       |         |        |      |       |      |      |        |      |    |     |      |        |         |        |       |       |         |       |       |        |          |         |       |     |      |          |       \n",
            "The/DT sun/NN dipped/VBD below/IN the/DT horizon/NN ,/, casting/VBG a/DT warm/JJ glow/NN over/IN the/DT quiet/JJ town/NN ./. chirped/VBD softly/RB as/IN the/DT last/JJ rays/NNS of/IN light/NN danced/VBN on/IN the/DT rippling/VBG surface/NN of/IN the/DT river/NN ./. Along/IN the/DT narrow/JJ streets/NNS ,/, people/NNS bustled/VBD about/RB ,/, preparing/VBG for/IN the/DT evening/NN ahead/RB ./. laughed/VBD as/IN they/PRP played/VBD under/IN the/DT dimming/NN sky/NN ,/, their/PRP$ joy/NN echoing/VBG through/IN the/DT alleys/NNS ./. Meanwhile/RB ,/, the/DT smell/NN of/IN freshly/JJ baked/VBN bread/NN wafted/VBN from/IN a/DT nearby/JJ bakery/NN ,/, filling/VBG the/DT air/NN with/IN a/DT comforting/VBG aroma/NN ./. The/DT world/NN seemed/VBD to/TO slow/VB down/RP in/IN this/DT moment/NN ,/, as/IN if/IN time/NN itself/PRP was/VBD taking/VBG a/DT breath/NN before/IN the/DT night/NN fully/RB embraced/VBD the/DT town/NN ./. Birds/NNP Children/NNP\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding\n"
      ],
      "metadata": {
        "id": "7ovy4LLndpAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hello\")"
      ],
      "metadata": {
        "id": "ZFHxp1Zfa0il",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105d1dc2-fe0d-49d9-81e2-37f800f3ba9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One Hot Encoding\n",
        "# One hot encoding is a technique that we use to represent categorical variables as numerical values in a machine learning model."
      ],
      "metadata": {
        "id": "C0X8MnkCd0hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding using OneHotEncoder of Scikit-Learn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#Building a dummy employee dataset for example\n",
        "data = {'Employee id': [10, 20, 15, 25, 30],\n",
        "        'Gender': ['M', 'F', 'F', 'M', 'F'],\n",
        "        'Remarks': ['Good', 'Nice', 'Good', 'Great', 'Nice'],\n",
        "        }\n",
        "#Converting into a Pandas dataframe\n",
        "df = pd.DataFrame(data)\n",
        "#Print the dataframe:\n",
        "print(f\"Employee data : \\n{df}\")\n",
        "\n",
        "#Extract categorical columns from the dataframe\n",
        "#Here we extract the columns with object datatype as they are the categorical columns\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "#Initialize OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Apply one-hot encoding to the categorical columns\n",
        "one_hot_encoded = encoder.fit_transform(df[categorical_columns])\n",
        "\n",
        "#Create a DataFrame with the one-hot encoded columns\n",
        "#We use get_feature_names_out() to get the column names for the encoded data\n",
        "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
        "\n",
        "# Concatenate the one-hot encoded dataframe with the original dataframe\n",
        "df_encoded = pd.concat([df, one_hot_df], axis=1)\n",
        "\n",
        "# Drop the original categorical columns\n",
        "df_encoded = df_encoded.drop(categorical_columns, axis=1)\n",
        "\n",
        "# Display the resulting dataframe\n",
        "print(f\"Encoded Employee data : \\n{df_encoded}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sJCK362h-z7",
        "outputId": "24b8afe7-8978-4472-ab6b-bd688d8fa5b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Employee data : \n",
            "   Employee id Gender Remarks\n",
            "0           10      M    Good\n",
            "1           20      F    Nice\n",
            "2           15      F    Good\n",
            "3           25      M   Great\n",
            "4           30      F    Nice\n",
            "Encoded Employee data : \n",
            "   Employee id  Gender_F  Gender_M  Remarks_Good  Remarks_Great  Remarks_Nice\n",
            "0           10       0.0       1.0           1.0            0.0           0.0\n",
            "1           20       1.0       0.0           0.0            0.0           1.0\n",
            "2           15       1.0       0.0           1.0            0.0           0.0\n",
            "3           25       0.0       1.0           0.0            1.0           0.0\n",
            "4           30       1.0       0.0           0.0            0.0           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Program for demonstration of one hot encoding\n",
        "\n",
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# import the data required\n",
        "data = pd.DataFrame(data)\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hByNZ2lmhry0",
        "outputId": "e31f5fa5-8127-4999-b2d7-bf159e59165c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Employee id Gender Remarks\n",
            "0           10      M    Good\n",
            "1           20      F    Nice\n",
            "2           15      F    Good\n",
            "3           25      M   Great\n",
            "4           30      F    Nice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Gender'].unique()\n",
        "data['Remarks'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik_FoxOmiEpU",
        "outputId": "45ce4468-8b80-4058-ee44-b03f555231c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Good', 'Nice', 'Great'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Gender'].value_counts()\n",
        "data['Remarks'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "lyeRDZ04id-4",
        "outputId": "eb57392c-4f76-458c-b63c-7e376ff9bdaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Remarks\n",
              "Good     2\n",
              "Nice     2\n",
              "Great    1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Remarks</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Good</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nice</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Great</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oneHotEncodedData = pd.get_dummies(data, columns = ['Gender', 'Remarks'])\n",
        "oneHotEncodedData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "b4sg-ITLixhn",
        "outputId": "a7d5bb72-d5aa-4ab9-e7f0-e24c68f8d985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Employee id  Gender_F  Gender_M  Remarks_Good  Remarks_Great  Remarks_Nice\n",
              "0           10     False      True          True          False         False\n",
              "1           20      True     False         False          False          True\n",
              "2           15      True     False          True          False         False\n",
              "3           25     False      True         False           True         False\n",
              "4           30      True     False         False          False          True"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6cac349a-3c1e-416a-a4fd-0425c5113a8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Employee id</th>\n",
              "      <th>Gender_F</th>\n",
              "      <th>Gender_M</th>\n",
              "      <th>Remarks_Good</th>\n",
              "      <th>Remarks_Great</th>\n",
              "      <th>Remarks_Nice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cac349a-3c1e-416a-a4fd-0425c5113a8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6cac349a-3c1e-416a-a4fd-0425c5113a8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6cac349a-3c1e-416a-a4fd-0425c5113a8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-22cd9fce-1a61-48a6-92e7-d311d863e51f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22cd9fce-1a61-48a6-92e7-d311d863e51f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-22cd9fce-1a61-48a6-92e7-d311d863e51f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9129e6a2-c04c-4c58-acb8-71eb2c025db3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('oneHotEncodedData')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9129e6a2-c04c-4c58-acb8-71eb2c025db3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('oneHotEncodedData');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "oneHotEncodedData",
              "summary": "{\n  \"name\": \"oneHotEncodedData\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Employee id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 10,\n        \"max\": 30,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          20,\n          30,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender_F\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender_M\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Remarks_Good\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Remarks_Great\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Remarks_Nice\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Bag of Words model\n",
        "word2count = {}\n",
        "for data in dataset:\n",
        "    words = nltk.word_tokenize(data)\n",
        "    for word in words:\n",
        "        if word not in word2count.keys():\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "\n",
        "# Bag of Words\n",
        "X = []\n",
        "for data in dataset:\n",
        "    vector = []\n",
        "    for word in freq_words:\n",
        "        if word in nltk.word_tokenize(data):\n",
        "            vector.append(1)\n",
        "        else:\n",
        "            vector.append(0)\n",
        "    X.append(vector)\n",
        "X = np.asarray(X)"
      ],
      "metadata": {
        "id": "iBKSpBgLjMDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF - IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "d0 = 'good boy'\n",
        "d1 = 'good girl'\n",
        "d2 = 'good girl boy'\n",
        "\n",
        "# merge documents into a single corpus\n",
        "string = [d0, d1, d2]\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "result = tfidf.fit_transform(string)\n",
        "\n",
        "# get indexing\n",
        "print('\\nWord indexes:')\n",
        "print(tfidf.vocabulary_)\n",
        "\n",
        "# display tf-idf values\n",
        "print('\\ntf-idf value:')\n",
        "print(result)\n",
        "\n",
        "# in matrix form\n",
        "print('\\ntf-idf values in matrix form:')\n",
        "print(result.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFQz3JDPuE0W",
        "outputId": "2472c87f-5258-49df-e359-13f18fea951f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word indexes:\n",
            "{'good': 2, 'boy': 0, 'girl': 1}\n",
            "\n",
            "tf-idf value:\n",
            "  (0, 2)\t0.6133555370249717\n",
            "  (0, 0)\t0.7898069290660905\n",
            "  (1, 2)\t0.6133555370249717\n",
            "  (1, 1)\t0.7898069290660905\n",
            "  (2, 2)\t0.48133416873660545\n",
            "  (2, 0)\t0.6198053799406072\n",
            "  (2, 1)\t0.6198053799406072\n",
            "\n",
            "tf-idf values in matrix form:\n",
            "[[0.78980693 0.         0.61335554]\n",
            " [0.         0.78980693 0.61335554]\n",
            " [0.61980538 0.61980538 0.48133417]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJYZtevjwZZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec"
      ],
      "metadata": {
        "id": "OD8HKFCUAVGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtH-467xAcMx",
        "outputId": "f0298ac7-37d3-42f5-a613-6c705280d0cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "92ot_KphBN-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors"
      ],
      "metadata": {
        "id": "qPJCA1-bBQnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0fOMxaeB93a",
        "outputId": "0e532a8a-745c-47e7-f7d4-8b9a7fcd3d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_king = wv['king']\n",
        "print(vec_king)\n",
        "vec_ai = wv['ai']\n",
        "print(vec_ai)\n",
        "try:\n",
        "  vec_machine = wv['machine learning']\n",
        "  print(vec_machine)\n",
        "except:\n",
        "  print(\"Word not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY7QEnrpCXdG",
        "outputId": "265b0a82-f71a-4a31-bd7f-ed7b72435a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.25976562e-01  2.97851562e-02  8.60595703e-03  1.39648438e-01\n",
            " -2.56347656e-02 -3.61328125e-02  1.11816406e-01 -1.98242188e-01\n",
            "  5.12695312e-02  3.63281250e-01 -2.42187500e-01 -3.02734375e-01\n",
            " -1.77734375e-01 -2.49023438e-02 -1.67968750e-01 -1.69921875e-01\n",
            "  3.46679688e-02  5.21850586e-03  4.63867188e-02  1.28906250e-01\n",
            "  1.36718750e-01  1.12792969e-01  5.95703125e-02  1.36718750e-01\n",
            "  1.01074219e-01 -1.76757812e-01 -2.51953125e-01  5.98144531e-02\n",
            "  3.41796875e-01 -3.11279297e-02  1.04492188e-01  6.17675781e-02\n",
            "  1.24511719e-01  4.00390625e-01 -3.22265625e-01  8.39843750e-02\n",
            "  3.90625000e-02  5.85937500e-03  7.03125000e-02  1.72851562e-01\n",
            "  1.38671875e-01 -2.31445312e-01  2.83203125e-01  1.42578125e-01\n",
            "  3.41796875e-01 -2.39257812e-02 -1.09863281e-01  3.32031250e-02\n",
            " -5.46875000e-02  1.53198242e-02 -1.62109375e-01  1.58203125e-01\n",
            " -2.59765625e-01  2.01416016e-02 -1.63085938e-01  1.35803223e-03\n",
            " -1.44531250e-01 -5.68847656e-02  4.29687500e-02 -2.46582031e-02\n",
            "  1.85546875e-01  4.47265625e-01  9.58251953e-03  1.31835938e-01\n",
            "  9.86328125e-02 -1.85546875e-01 -1.00097656e-01 -1.33789062e-01\n",
            " -1.25000000e-01  2.83203125e-01  1.23046875e-01  5.32226562e-02\n",
            " -1.77734375e-01  8.59375000e-02 -2.18505859e-02  2.05078125e-02\n",
            " -1.39648438e-01  2.51464844e-02  1.38671875e-01 -1.05468750e-01\n",
            "  1.38671875e-01  8.88671875e-02 -7.51953125e-02 -2.13623047e-02\n",
            "  1.72851562e-01  4.63867188e-02 -2.65625000e-01  8.91113281e-03\n",
            "  1.49414062e-01  3.78417969e-02  2.38281250e-01 -1.24511719e-01\n",
            " -2.17773438e-01 -1.81640625e-01  2.97851562e-02  5.71289062e-02\n",
            " -2.89306641e-02  1.24511719e-02  9.66796875e-02 -2.31445312e-01\n",
            "  5.81054688e-02  6.68945312e-02  7.08007812e-02 -3.08593750e-01\n",
            " -2.14843750e-01  1.45507812e-01 -4.27734375e-01 -9.39941406e-03\n",
            "  1.54296875e-01 -7.66601562e-02  2.89062500e-01  2.77343750e-01\n",
            " -4.86373901e-04 -1.36718750e-01  3.24218750e-01 -2.46093750e-01\n",
            " -3.03649902e-03 -2.11914062e-01  1.25000000e-01  2.69531250e-01\n",
            "  2.04101562e-01  8.25195312e-02 -2.01171875e-01 -1.60156250e-01\n",
            " -3.78417969e-02 -1.20117188e-01  1.15234375e-01 -4.10156250e-02\n",
            " -3.95507812e-02 -8.98437500e-02  6.34765625e-03  2.03125000e-01\n",
            "  1.86523438e-01  2.73437500e-01  6.29882812e-02  1.41601562e-01\n",
            " -9.81445312e-02  1.38671875e-01  1.82617188e-01  1.73828125e-01\n",
            "  1.73828125e-01 -2.37304688e-01  1.78710938e-01  6.34765625e-02\n",
            "  2.36328125e-01 -2.08984375e-01  8.74023438e-02 -1.66015625e-01\n",
            " -7.91015625e-02  2.43164062e-01 -8.88671875e-02  1.26953125e-01\n",
            " -2.16796875e-01 -1.73828125e-01 -3.59375000e-01 -8.25195312e-02\n",
            " -6.49414062e-02  5.07812500e-02  1.35742188e-01 -7.47070312e-02\n",
            " -1.64062500e-01  1.15356445e-02  4.45312500e-01 -2.15820312e-01\n",
            " -1.11328125e-01 -1.92382812e-01  1.70898438e-01 -1.25000000e-01\n",
            "  2.65502930e-03  1.92382812e-01 -1.74804688e-01  1.39648438e-01\n",
            "  2.92968750e-01  1.13281250e-01  5.95703125e-02 -6.39648438e-02\n",
            "  9.96093750e-02 -2.72216797e-02  1.96533203e-02  4.27246094e-02\n",
            " -2.46093750e-01  6.39648438e-02 -2.25585938e-01 -1.68945312e-01\n",
            "  2.89916992e-03  8.20312500e-02  3.41796875e-01  4.32128906e-02\n",
            "  1.32812500e-01  1.42578125e-01  7.61718750e-02  5.98144531e-02\n",
            " -1.19140625e-01  2.74658203e-03 -6.29882812e-02 -2.72216797e-02\n",
            " -4.82177734e-03 -8.20312500e-02 -2.49023438e-02 -4.00390625e-01\n",
            " -1.06933594e-01  4.24804688e-02  7.76367188e-02 -1.16699219e-01\n",
            "  7.37304688e-02 -9.22851562e-02  1.07910156e-01  1.58203125e-01\n",
            "  4.24804688e-02  1.26953125e-01  3.61328125e-02  2.67578125e-01\n",
            " -1.01074219e-01 -3.02734375e-01 -5.76171875e-02  5.05371094e-02\n",
            "  5.26428223e-04 -2.07031250e-01 -1.38671875e-01 -8.97216797e-03\n",
            " -2.78320312e-02 -1.41601562e-01  2.07031250e-01 -1.58203125e-01\n",
            "  1.27929688e-01  1.49414062e-01 -2.24609375e-02 -8.44726562e-02\n",
            "  1.22558594e-01  2.15820312e-01 -2.13867188e-01 -3.12500000e-01\n",
            " -3.73046875e-01  4.08935547e-03  1.07421875e-01  1.06933594e-01\n",
            "  7.32421875e-02  8.97216797e-03 -3.88183594e-02 -1.29882812e-01\n",
            "  1.49414062e-01 -2.14843750e-01 -1.83868408e-03  9.91210938e-02\n",
            "  1.57226562e-01 -1.14257812e-01 -2.05078125e-01  9.91210938e-02\n",
            "  3.69140625e-01 -1.97265625e-01  3.54003906e-02  1.09375000e-01\n",
            "  1.31835938e-01  1.66992188e-01  2.35351562e-01  1.04980469e-01\n",
            " -4.96093750e-01 -1.64062500e-01 -1.56250000e-01 -5.22460938e-02\n",
            "  1.03027344e-01  2.43164062e-01 -1.88476562e-01  5.07812500e-02\n",
            " -9.37500000e-02 -6.68945312e-02  2.27050781e-02  7.61718750e-02\n",
            "  2.89062500e-01  3.10546875e-01 -5.37109375e-02  2.28515625e-01\n",
            "  2.51464844e-02  6.78710938e-02 -1.21093750e-01 -2.15820312e-01\n",
            " -2.73437500e-01 -3.07617188e-02 -3.37890625e-01  1.53320312e-01\n",
            "  2.33398438e-01 -2.08007812e-01  3.73046875e-01  8.20312500e-02\n",
            "  2.51953125e-01 -7.61718750e-02 -4.66308594e-02 -2.23388672e-02\n",
            "  2.99072266e-02 -5.93261719e-02 -4.66918945e-03 -2.44140625e-01\n",
            " -2.09960938e-01 -2.87109375e-01 -4.54101562e-02 -1.77734375e-01\n",
            " -2.79296875e-01 -8.59375000e-02  9.13085938e-02  2.51953125e-01]\n",
            "[-1.34765625e-01  2.87109375e-01 -5.15136719e-02  1.08886719e-01\n",
            " -1.00097656e-01  4.76074219e-03 -5.66406250e-02 -6.49414062e-02\n",
            " -1.01562500e-01  1.68945312e-01 -1.94335938e-01 -2.71484375e-01\n",
            " -2.91015625e-01 -7.26318359e-03 -2.51953125e-01  1.29882812e-01\n",
            " -1.82617188e-01  6.15234375e-02  1.83105469e-02  2.65625000e-01\n",
            " -4.19921875e-01 -2.08007812e-01  1.69921875e-01 -2.79296875e-01\n",
            " -4.06250000e-01 -2.48046875e-01  4.49218750e-02  1.23046875e-01\n",
            " -2.79296875e-01 -4.34570312e-02 -7.76367188e-02 -6.73828125e-02\n",
            " -9.76562500e-02 -1.06201172e-02 -1.83593750e-01 -9.86328125e-02\n",
            " -1.41601562e-01  2.65625000e-01  1.21459961e-02 -1.11816406e-01\n",
            "  2.02941895e-03  1.57226562e-01  1.94091797e-02  3.28125000e-01\n",
            " -1.55273438e-01 -1.74804688e-01  1.89208984e-03  1.04003906e-01\n",
            "  1.10839844e-01  2.25585938e-01 -2.37304688e-01  3.63281250e-01\n",
            " -2.31933594e-02 -1.33666992e-02 -2.25585938e-01  2.59765625e-01\n",
            " -3.41796875e-01 -9.37500000e-02  1.53320312e-01 -4.04296875e-01\n",
            " -2.10937500e-01  1.27929688e-01 -5.15136719e-02 -6.93359375e-02\n",
            "  1.75781250e-02 -1.92382812e-01 -1.12304688e-02 -9.47265625e-02\n",
            " -3.44238281e-02  8.88671875e-02  1.40625000e-01 -7.51953125e-02\n",
            " -1.28906250e-01  2.99072266e-02 -4.90722656e-02  5.00488281e-02\n",
            "  3.97949219e-02  2.34375000e-02  4.63867188e-03  2.75390625e-01\n",
            "  3.00781250e-01  1.08886719e-01  5.76171875e-02 -7.42187500e-02\n",
            "  1.61132812e-01  1.80816650e-03  3.08837891e-02  9.57031250e-02\n",
            "  1.83593750e-01  8.42285156e-03  8.39843750e-02  1.24511719e-01\n",
            " -1.48437500e-01 -3.35937500e-01  3.22265625e-01  1.85546875e-01\n",
            " -1.19628906e-01 -1.30859375e-01  1.30859375e-01 -1.66015625e-01\n",
            " -2.92968750e-01  2.35351562e-01 -1.89453125e-01  2.98828125e-01\n",
            "  3.05175781e-02  3.80859375e-01 -7.37304688e-02  1.95312500e-01\n",
            "  1.68945312e-01  1.71875000e-01 -3.43750000e-01 -2.36328125e-01\n",
            " -2.19726562e-03  5.95703125e-02 -1.22558594e-01 -5.20019531e-02\n",
            " -3.88183594e-02 -4.06250000e-01 -1.42578125e-01 -7.37304688e-02\n",
            "  4.69970703e-03 -1.64062500e-01 -1.27929688e-01  1.60156250e-01\n",
            "  1.92382812e-01 -3.18359375e-01 -2.20703125e-01 -1.13769531e-01\n",
            "  2.10937500e-01  1.07910156e-01 -4.97436523e-03  1.43554688e-01\n",
            "  7.27539062e-02 -1.45507812e-01 -3.82812500e-01  7.47070312e-02\n",
            " -1.57226562e-01 -1.06933594e-01  3.55468750e-01 -8.93554688e-02\n",
            "  3.51562500e-01 -2.17773438e-01 -1.26953125e-01  1.44531250e-01\n",
            " -4.51660156e-02 -9.70458984e-03 -1.06445312e-01  3.35937500e-01\n",
            " -2.30468750e-01 -1.70898438e-01 -9.15527344e-03 -4.07714844e-02\n",
            "  1.68457031e-02  1.29882812e-01 -1.22558594e-01 -3.63281250e-01\n",
            "  2.39257812e-01  3.24218750e-01 -1.44531250e-01 -2.35351562e-01\n",
            " -5.59082031e-02  2.01171875e-01 -7.27539062e-02  2.90527344e-02\n",
            " -2.13867188e-01 -1.55273438e-01  1.34765625e-01  3.16406250e-01\n",
            " -1.68945312e-01  5.29785156e-02 -3.02734375e-02 -7.27539062e-02\n",
            " -1.17187500e-01 -1.92382812e-01  1.54296875e-01  3.16406250e-01\n",
            "  3.26171875e-01 -1.42578125e-01  4.58984375e-01 -9.86328125e-02\n",
            "  1.45507812e-01 -1.09863281e-01 -1.01562500e-01 -8.60595703e-03\n",
            " -7.53784180e-03  2.65625000e-01  5.81054688e-02 -1.44531250e-01\n",
            " -1.58203125e-01  8.15429688e-02  1.66015625e-01  6.17675781e-02\n",
            " -2.79541016e-02 -1.35742188e-01  1.51367188e-01  2.25585938e-01\n",
            "  1.99218750e-01 -1.58203125e-01  8.49609375e-02 -1.40625000e-01\n",
            " -1.10351562e-01  1.64062500e-01 -2.87109375e-01 -2.06054688e-01\n",
            "  6.34765625e-02 -4.41406250e-01  4.14062500e-01 -1.50756836e-02\n",
            " -1.53320312e-01  1.49414062e-01  9.96093750e-02 -1.88476562e-01\n",
            " -3.35937500e-01 -2.88085938e-02 -1.53320312e-01  1.38671875e-01\n",
            "  1.14257812e-01 -1.37939453e-02 -4.04296875e-01  1.45263672e-02\n",
            "  2.50000000e-01  1.39648438e-01 -2.67028809e-04  4.78515625e-02\n",
            "  4.93164062e-02 -1.51367188e-01  2.10937500e-01  1.23535156e-01\n",
            "  1.58691406e-02  8.15429688e-02  1.00708008e-02 -1.72119141e-02\n",
            "  2.66113281e-02 -1.16699219e-01 -6.10351562e-02  1.51977539e-02\n",
            " -1.30859375e-01  7.86132812e-02  1.25732422e-02  1.59179688e-01\n",
            " -2.68554688e-02  1.83593750e-01 -1.07421875e-01 -5.85937500e-02\n",
            " -4.49218750e-02  6.98242188e-02 -1.98242188e-01  2.96875000e-01\n",
            "  5.81054688e-02 -2.65625000e-01 -1.28906250e-01  1.93359375e-01\n",
            "  3.71093750e-02 -1.03027344e-01 -9.86328125e-02 -2.84423828e-02\n",
            " -3.41796875e-01 -1.68945312e-01  3.30078125e-01  2.90527344e-02\n",
            " -6.64062500e-02  4.37500000e-01  3.12500000e-01 -2.10937500e-01\n",
            " -1.52343750e-01  9.08203125e-02 -2.69775391e-02  1.32812500e-01\n",
            "  4.02832031e-02 -2.40234375e-01 -2.59765625e-01 -1.25000000e-01\n",
            " -1.15722656e-01 -1.26953125e-01  1.48437500e-01  1.87500000e-01\n",
            " -2.22656250e-01 -1.21582031e-01 -8.44726562e-02  2.29492188e-01\n",
            " -3.35937500e-01  5.11718750e-01  3.28125000e-01 -8.25195312e-02\n",
            "  1.33789062e-01  3.06640625e-01  5.39550781e-02  7.08007812e-02\n",
            " -1.85546875e-01  1.52343750e-01  1.87988281e-02 -2.27050781e-02\n",
            " -1.33789062e-01  2.34375000e-01  1.62109375e-01  1.92871094e-02\n",
            " -8.54492188e-02 -5.34667969e-02 -1.66992188e-01  1.38549805e-02]\n",
            "Word not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv.most_similar('ai')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqiwv71zDAet",
        "outputId": "f676c038-311f-40a5-d261-ea2cd7ebbfde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('che', 0.6292661428451538),\n",
              " ('te', 0.6197360754013062),\n",
              " ('essere', 0.5948276519775391),\n",
              " ('', 0.593923032283783),\n",
              " ('mai', 0.5895475149154663),\n",
              " ('voi', 0.5879174470901489),\n",
              " ('tutto', 0.5835935473442078),\n",
              " ('ti', 0.5791943073272705),\n",
              " ('tutti_i', 0.576695442199707),\n",
              " ('questo', 0.5765190124511719)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv.most_similar('google')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95CYnGbKDHpn",
        "outputId": "3ee61feb-c056-40a4-b17d-a17d57ac6784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('google.com', 0.6711485981941223),\n",
              " ('google_yahoo', 0.6488178968429565),\n",
              " ('wikipedia', 0.643608033657074),\n",
              " ('www.google.com', 0.6258559226989746),\n",
              " ('googled', 0.6166064143180847),\n",
              " ('googling', 0.6086059212684631),\n",
              " ('slashdot', 0.5964587330818176),\n",
              " ('lifehacker', 0.5948858857154846),\n",
              " ('gizmodo', 0.5884420275688171),\n",
              " ('inurl', 0.5882638692855835)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity Between crickrt and sports is \", wv.similarity('cricket', 'sports'))\n",
        "print(\"Similarity Between shaharukh and king is \", wv.similarity('shahrukh', 'king'))\n",
        "print(\"Similarity Between good and bad is \", wv.similarity('good', 'bad'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHMBdPtsDX44",
        "outputId": "68fa0529-08f1-4d3a-db55-96c241355759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Between crickrt and sports is  0.40087253\n",
            "Similarity Between shaharukh and king is  0.2531487\n",
            "Similarity Between good and bad is  0.7190051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec = wv['king'] - wv['man'] + wv['woman']\n",
        "vec\n",
        "wv.most_similar([vec])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAuLg1wjDg3d",
        "outputId": "d5588226-8c43-4d4d-caa7-531a522c46cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('king', 0.8449392318725586),\n",
              " ('queen', 0.7300517559051514),\n",
              " ('monarch', 0.645466148853302),\n",
              " ('princess', 0.6156251430511475),\n",
              " ('crown_prince', 0.5818676352500916),\n",
              " ('prince', 0.5777117609977722),\n",
              " ('kings', 0.5613663792610168),\n",
              " ('sultan', 0.5376775860786438),\n",
              " ('Queen_Consort', 0.5344247817993164),\n",
              " ('queens', 0.5289887189865112)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kLBjaDb7F7FY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}